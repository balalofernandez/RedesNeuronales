{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1c16c9",
   "metadata": {},
   "source": [
    "## En este apartado vamos a ver Conceptos básicos de **TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e82f2",
   "metadata": {},
   "source": [
    "## Conceptos generales\n",
    "\n",
    "Los **Tensores** son arrays de una dimensión variable que muestran una relación. En la práctica lo que vamos a tener son varios tensores de un tamaño pequeño. Existen los siguientes tipos:\n",
    "\n",
    "  * Un **escalar** es un 0-d Array (un tensor de orden 0).  Por ejemplo, `\"Howdy\"` o `5`\n",
    "  * Un **vector** es un 1-d Array (un tensor de orden 1).  Por ejemplo, `[2, 3, 5, 7, 11]` o `[5]`\n",
    "  * Una **matriz** es un 2-d Array (un tensor de orden 2).  Por ejemplo, `[[3.1, 8.2, 5.9][4.3, -2.7, 6.5]]`\n",
    "\n",
    "Las **operaciones** nos permiten crear, manipular o destruir tensores. \n",
    "\n",
    "Una **gráfica** en TensorFlow es simplemente una gráfica para estructurar datos\n",
    "\n",
    "Tensors can be stored in the graph as **constants** or **variables**. As you might guess, constants hold tensors whose values can't change, while variables hold tensors whose values can change. However, what you may not have guessed is that constants and variables are just more operations in the graph. A constant is an operation that always returns the same tensor value. A variable is an operation that will return whichever tensor has been assigned to it.\n",
    "\n",
    "To define a constant, use the `tf.constant` operator and pass in its value. For example:\n",
    "\n",
    "```\n",
    "  x = tf.constant(5.2)\n",
    "```\n",
    "\n",
    "Similarly, you can create a variable like this:\n",
    "\n",
    "```\n",
    "  y = tf.Variable([5])\n",
    "```\n",
    "\n",
    "Or you can create the variable first and then subsequently assign a value like this (note that you always have to specify a default value):\n",
    "\n",
    "```\n",
    "  y = tf.Variable([0])\n",
    "  y = y.assign([5])\n",
    "```\n",
    "\n",
    "Once you've defined some constants or variables, you can combine them with other operations like `tf.add`. When you evaluate the `tf.add` operation, it will call your `tf.constant` or `tf.Variable` operations to get their values and then return a new tensor with the sum of those values.\n",
    "\n",
    "Graphs must run within a TensorFlow **session**, which holds the state for the graph(s) it runs:\n",
    "\n",
    "```\n",
    "with tf.Session() as sess:\n",
    "  initialization = tf.global_variables_initializer()\n",
    "  print(y.eval())\n",
    "```\n",
    "\n",
    "When working with `tf.Variable`s, you must explicitly initialize them by calling `tf.global_variables_initializer` at the start of your session, as shown above.\n",
    "\n",
    "**Note:** A session can distribute graph execution across multiple machines (assuming the program is run on some distributed computation framework). For more information, see [Distributed TensorFlow](https://www.tensorflow.org/deploy/distributed).\n",
    "\n",
    "### Summary\n",
    "\n",
    "TensorFlow programming is essentially a two-step process:\n",
    "\n",
    "  1. Assemble constants, variables, and operations into a graph.\n",
    "  2. Evaluate those constants, variables and operations within a session."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551bd4d",
   "metadata": {},
   "source": [
    "### Programa simple de TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b8ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "#OJO QUE EN EL NOTEBOOK TRABAJAMOS CON TENSORFLOW 1.0 \n",
    "#%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3a3e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a graph.\n",
    "g = tf.Graph()\n",
    "\n",
    "# Establish the graph as the \"default\" graph.\n",
    "with g.as_default():\n",
    "  # Assemble a graph consisting of the following three operations:\n",
    "  #   * Two tf.constant operations to create the operands.\n",
    "  #   * One tf.add operation to add the two operands.\n",
    "  x = tf.constant(8, name=\"x_const\")\n",
    "  y = tf.constant(5, name=\"y_const\")\n",
    "  my_sum = tf.add(x, y, name=\"x_y_sum\")\n",
    "\n",
    "\n",
    "  # Now create a session.\n",
    "  # The session will run the default graph.\n",
    "  with tf.compat.v1.Session() as sess:\n",
    "    print(my_sum.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4241c09f",
   "metadata": {},
   "source": [
    "### Entrenar un modelo mediante regresión lineal:\n",
    "\n",
    "Podemos definir una función de entrada al `LinearRegressor` de la siguiente forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd9131a",
   "metadata": {},
   "source": [
    "Primero vamos a recolectar los datos necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9421ee6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8312074bd058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Use gradient descent as the optimizer for training the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmy_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0000001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mmy_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_gradients_by_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "source": [
    "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
    "california_housing_dataframe = california_housing_dataframe.reindex(\n",
    "    np.random.permutation(california_housing_dataframe.index))\n",
    "california_housing_dataframe[\"median_house_value\"] /= 1000.0\n",
    "\n",
    "# Define the input feature: total_rooms.\n",
    "my_feature = california_housing_dataframe[[\"total_rooms\"]]\n",
    "\n",
    "# Configure a numeric feature column for total_rooms.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"total_rooms\")]\n",
    "\n",
    "# Define the label.\n",
    "targets = california_housing_dataframe[\"median_house_value\"]\n",
    "\n",
    "# Use gradient descent as the optimizer for training the model.\n",
    "my_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0000001)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "# Configure the linear regression model with our feature columns and optimizer.\n",
    "# Set a learning rate of 0.0000001 for Gradient Descent.\n",
    "linear_regressor = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns,\n",
    "    optimizer=my_optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214626d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "    \"\"\"Trains a linear regression model of one feature.\n",
    "  \n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      targets: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "  \n",
    "    # Convert pandas data into a dict of np arrays.\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(buffer_size=10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    return features, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
